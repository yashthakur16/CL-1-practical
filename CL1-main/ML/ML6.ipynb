{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KrWZujHI-2mo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1  # Player 1 starts\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1\n",
    "        return self.board\n",
    "\n",
    "    def display_board(self):\n",
    "        symbols = {1: 'X', -1: 'O', 0: ' '}\n",
    "        for row in self.board:\n",
    "            print(\" | \".join([symbols[cell] for cell in row]))\n",
    "        print(\"-------------\")\n",
    "\n",
    "\n",
    "    def is_winner(self, player):\n",
    "        # Check if the specified player has won\n",
    "        return any([\n",
    "            all(self.board[i, :] == player) for i in range(3)\n",
    "        ]) or any([\n",
    "            all(self.board[:, i] == player) for i in range(3)\n",
    "        ]) or all([\n",
    "            self.board[i, i] == player for i in range(3)\n",
    "        ]) or all([\n",
    "            self.board[i, 2 - i] == player for i in range(3)\n",
    "        ])\n",
    "\n",
    "    def is_draw(self):\n",
    "        # Check if the game is a draw (no winner, board is full)\n",
    "        return np.all(self.board != 0) and not self.is_winner(1) and not self.is_winner(-1)\n",
    "\n",
    "    def available_actions(self):\n",
    "        # List of available actions (empty cells)\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
    "\n",
    "    def step(self, action):\n",
    "        # Apply an action for the current player\n",
    "        if self.board[action] != 0:\n",
    "            raise ValueError(\"Invalid action: cell already occupied\")\n",
    "\n",
    "        self.board[action] = self.current_player\n",
    "\n",
    "        # Check game outcome\n",
    "        if self.is_winner(self.current_player):\n",
    "            reward = 1\n",
    "            done = True\n",
    "        elif self.is_draw():\n",
    "            reward = 0\n",
    "            done = True\n",
    "        else:\n",
    "            reward = 0\n",
    "            done = False\n",
    "            self.current_player *= -1  # Switch player\n",
    "\n",
    "        return self.board, reward, done, None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FMM1SgIPA8Zn"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, learning_rate=0.1, discount_factor=0.9, epsilon=1.0, epsilon_decay=0.99):\n",
    "        self.q_table = {}  # Initialize Q-table as a dictionary\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "\n",
    "    def get_state(self, board):\n",
    "        # Convert the board to a tuple of tuples for dictionary key\n",
    "        return tuple(map(tuple, board))\n",
    "\n",
    "    def choose_action(self, state, available_actions):\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(available_actions)  # Explore\n",
    "        else:\n",
    "            # Exploit: choose action with max Q-value for the state\n",
    "            q_values = [self.q_table.get((state, action), 0) for action in available_actions]\n",
    "            max_q = max(q_values)\n",
    "            return random.choice([action for action, q in zip(available_actions, q_values) if q == max_q])\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state, next_available_actions):\n",
    "        # Update the Q-value using the Q-learning formula\n",
    "        old_q_value = self.q_table.get((state, action), 0)\n",
    "        next_q_values = [self.q_table.get((next_state, a), 0) for a in next_available_actions]\n",
    "        next_max_q = max(next_q_values) if next_q_values else 0\n",
    "\n",
    "        new_q_value = old_q_value + self.learning_rate * (reward + self.discount_factor * next_max_q - old_q_value)\n",
    "        self.q_table[(state, action)] = new_q_value\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        # Decay epsilon\n",
    "        self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PgfiWYqLBB5L"
   },
   "outputs": [],
   "source": [
    "def train(agent, environment, episodes=10000, display_games=5):\n",
    "    for episode in range(episodes):\n",
    "        state = environment.reset()\n",
    "        done = False\n",
    "\n",
    "        if episode < display_games:\n",
    "            print(f\"--- Training Game {episode + 1} ---\")\n",
    "            environment.display_board()\n",
    "\n",
    "        while not done:\n",
    "            state_key = agent.get_state(state)\n",
    "            available_actions = environment.available_actions()\n",
    "            action = agent.choose_action(state_key, available_actions)\n",
    "\n",
    "            # Take the action in the environment\n",
    "            next_state, reward, done, _ = environment.step(action)\n",
    "            if episode < display_games:  # Display for first few games\n",
    "                environment.display_board()  # Show board after each move\n",
    "\n",
    "            next_state_key = agent.get_state(next_state)\n",
    "            next_available_actions = environment.available_actions() if not done else []\n",
    "            agent.update_q_value(state_key, action, reward, next_state_key, next_available_actions)\n",
    "            state = next_state\n",
    "\n",
    "        agent.decay_epsilon()\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "def test(agent, environment, games=5):\n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    losses = 0\n",
    "\n",
    "    for game in range(games):\n",
    "        state = environment.reset()\n",
    "        done = False\n",
    "        print(f\"--- Testing Game {game + 1} ---\")\n",
    "        environment.display_board()\n",
    "\n",
    "        while not done:\n",
    "            state_key = agent.get_state(state)\n",
    "            available_actions = environment.available_actions()\n",
    "            action = agent.choose_action(state_key, available_actions)\n",
    "            state, reward, done, _ = environment.step(action)\n",
    "            environment.display_board()  # Show board after each move\n",
    "\n",
    "            # Opponent's turn (random)\n",
    "            if not done:\n",
    "                opponent_action = random.choice(environment.available_actions())\n",
    "                state, _, done, _ = environment.step(opponent_action)\n",
    "                environment.display_board()  # Show board after opponent's move\n",
    "\n",
    "        if reward == 1:\n",
    "            wins += 1\n",
    "        elif reward == 0:\n",
    "            draws += 1\n",
    "        else:\n",
    "            losses += 1\n",
    "\n",
    "    print(f\"Testing results: Wins: {wins}, Draws: {draws}, Losses: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YXkHm9q-71d",
    "outputId": "56edd69b-415b-4a04-c807-2a0fdd6897ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Game 1 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "X |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   | O\n",
      "X |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   | O\n",
      "X |   | X\n",
      "  |   |  \n",
      "-------------\n",
      "  |   | O\n",
      "X |   | X\n",
      "  | O |  \n",
      "-------------\n",
      "  |   | O\n",
      "X | X | X\n",
      "  | O |  \n",
      "-------------\n",
      "--- Training Game 2 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   | X\n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "O |   | X\n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "O | X | X\n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "O | X | X\n",
      "  |   |  \n",
      "  | O |  \n",
      "-------------\n",
      "O | X | X\n",
      "  |   |  \n",
      "X | O |  \n",
      "-------------\n",
      "O | X | X\n",
      "  |   | O\n",
      "X | O |  \n",
      "-------------\n",
      "O | X | X\n",
      "X |   | O\n",
      "X | O |  \n",
      "-------------\n",
      "O | X | X\n",
      "X |   | O\n",
      "X | O | O\n",
      "-------------\n",
      "O | X | X\n",
      "X | X | O\n",
      "X | O | O\n",
      "-------------\n",
      "--- Training Game 3 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   | O\n",
      "X |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  | X | O\n",
      "X |   |  \n",
      "-------------\n",
      "  |   | O\n",
      "  | X | O\n",
      "X |   |  \n",
      "-------------\n",
      "  | X | O\n",
      "  | X | O\n",
      "X |   |  \n",
      "-------------\n",
      "O | X | O\n",
      "  | X | O\n",
      "X |   |  \n",
      "-------------\n",
      "O | X | O\n",
      "  | X | O\n",
      "X | X |  \n",
      "-------------\n",
      "--- Training Game 4 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   | X\n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   | X\n",
      "  |   |  \n",
      "  | O |  \n",
      "-------------\n",
      "  |   | X\n",
      "  |   |  \n",
      "  | O | X\n",
      "-------------\n",
      "  |   | X\n",
      "O |   |  \n",
      "  | O | X\n",
      "-------------\n",
      "  |   | X\n",
      "O |   |  \n",
      "X | O | X\n",
      "-------------\n",
      "O |   | X\n",
      "O |   |  \n",
      "X | O | X\n",
      "-------------\n",
      "O |   | X\n",
      "O |   | X\n",
      "X | O | X\n",
      "-------------\n",
      "--- Training Game 5 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  | X |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  | X | O\n",
      "  |   |  \n",
      "-------------\n",
      "X |   |  \n",
      "  | X | O\n",
      "  |   |  \n",
      "-------------\n",
      "X |   |  \n",
      "  | X | O\n",
      "O |   |  \n",
      "-------------\n",
      "X |   | X\n",
      "  | X | O\n",
      "O |   |  \n",
      "-------------\n",
      "X | O | X\n",
      "  | X | O\n",
      "O |   |  \n",
      "-------------\n",
      "X | O | X\n",
      "  | X | O\n",
      "O |   | X\n",
      "-------------\n",
      "Training complete!\n",
      "--- Testing Game 1 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "O |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "O |   | X\n",
      "X |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "O |   | X\n",
      "X | O |  \n",
      "-------------\n",
      "  |   | X\n",
      "O |   | X\n",
      "X | O |  \n",
      "-------------\n",
      "  |   | X\n",
      "O | O | X\n",
      "X | O |  \n",
      "-------------\n",
      "  | X | X\n",
      "O | O | X\n",
      "X | O |  \n",
      "-------------\n",
      "O | X | X\n",
      "O | O | X\n",
      "X | O |  \n",
      "-------------\n",
      "O | X | X\n",
      "O | O | X\n",
      "X | O | X\n",
      "-------------\n",
      "--- Testing Game 2 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  | O |  \n",
      "  |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  | O |  \n",
      "  | X |  \n",
      "X |   |  \n",
      "-------------\n",
      "  | O | O\n",
      "  | X |  \n",
      "X |   |  \n",
      "-------------\n",
      "  | O | O\n",
      "  | X |  \n",
      "X |   | X\n",
      "-------------\n",
      "O | O | O\n",
      "  | X |  \n",
      "X |   | X\n",
      "-------------\n",
      "--- Testing Game 3 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  | O |  \n",
      "  |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  | O |  \n",
      "  |   |  \n",
      "X | X |  \n",
      "-------------\n",
      "  | O |  \n",
      "  |   | O\n",
      "X | X |  \n",
      "-------------\n",
      "  | O |  \n",
      "  | X | O\n",
      "X | X |  \n",
      "-------------\n",
      "  | O |  \n",
      "O | X | O\n",
      "X | X |  \n",
      "-------------\n",
      "  | O |  \n",
      "O | X | O\n",
      "X | X | X\n",
      "-------------\n",
      "--- Testing Game 4 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X |   | O\n",
      "-------------\n",
      "  | X |  \n",
      "  |   |  \n",
      "X |   | O\n",
      "-------------\n",
      "  | X |  \n",
      "  |   |  \n",
      "X | O | O\n",
      "-------------\n",
      "  | X |  \n",
      "  | X |  \n",
      "X | O | O\n",
      "-------------\n",
      "  | X |  \n",
      "O | X |  \n",
      "X | O | O\n",
      "-------------\n",
      "  | X | X\n",
      "O | X |  \n",
      "X | O | O\n",
      "-------------\n",
      "--- Testing Game 5 ---\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X |   |  \n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X |   | O\n",
      "-------------\n",
      "  |   |  \n",
      "  |   |  \n",
      "X | X | O\n",
      "-------------\n",
      "  | O |  \n",
      "  |   |  \n",
      "X | X | O\n",
      "-------------\n",
      "X | O |  \n",
      "  |   |  \n",
      "X | X | O\n",
      "-------------\n",
      "X | O |  \n",
      "  | O |  \n",
      "X | X | O\n",
      "-------------\n",
      "X | O | X\n",
      "  | O |  \n",
      "X | X | O\n",
      "-------------\n",
      "X | O | X\n",
      "O | O |  \n",
      "X | X | O\n",
      "-------------\n",
      "X | O | X\n",
      "O | O | X\n",
      "X | X | O\n",
      "-------------\n",
      "Testing results: Wins: 3, Draws: 2, Losses: 0\n"
     ]
    }
   ],
   "source": [
    "# Create environment and agent\n",
    "env = TicTacToe()\n",
    "agent = QLearningAgent()\n",
    "\n",
    "# Train the agent, displaying the first 5 games\n",
    "train(agent, env, episodes=10000, display_games=5)\n",
    "\n",
    "# Test the agent, displaying each game\n",
    "test(agent, env, games=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dVtaN_u2_EQy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
